{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T06:04:07.997497Z",
     "start_time": "2020-03-16T06:04:03.780096Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T06:21:29.117416Z",
     "start_time": "2020-03-16T06:21:29.051025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "id                                                                          \n",
       "0   18393       2     168    62.0    110     80            1     1      0   \n",
       "1   20228       1     156    85.0    140     90            3     1      0   \n",
       "2   18857       1     165    64.0    130     70            3     1      0   \n",
       "3   17623       2     169    82.0    150    100            1     1      0   \n",
       "4   17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "    alco  active  cardio  \n",
       "id                        \n",
       "0      0       1       0  \n",
       "1      0       1       1  \n",
       "2      0       0       1  \n",
       "3      0       1       1  \n",
       "4      0       0       0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cardio_train.csv\", delimiter=\";\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados limpos, sem valores faltantes. Todas as features s√£o num√©ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T06:21:30.115947Z",
     "start_time": "2020-03-16T06:21:30.106584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70000 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          70000 non-null  int64  \n",
      " 1   gender       70000 non-null  int64  \n",
      " 2   height       70000 non-null  int64  \n",
      " 3   weight       70000 non-null  float64\n",
      " 4   ap_hi        70000 non-null  int64  \n",
      " 5   ap_lo        70000 non-null  int64  \n",
      " 6   cholesterol  70000 non-null  int64  \n",
      " 7   gluc         70000 non-null  int64  \n",
      " 8   smoke        70000 non-null  int64  \n",
      " 9   alco         70000 non-null  int64  \n",
      " 10  active       70000 non-null  int64  \n",
      " 11  cardio       70000 non-null  int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 6.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vari√°vel alvo est√° com valores balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T06:21:31.274481Z",
     "start_time": "2020-03-16T06:21:31.179969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f193c0a2550>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAVHElEQVR4nO3df6xf9X3f8ecLGxL6gwLhhlEbCkutLYQkJnhgLd2UkQoMUmdSJRFsLRZjchaB1KhZF9JJhUKQGq1pNFqC5A4HE3UxjCTDi5y5HiXJooUfJhCDoYg7YOEGBqYGQkJHZPTeH9/Pbb6yv7YvH/y915f7fEhH33Pe5/M593Mii1fOOZ/v+aaqkCSpx2FzPQBJ0vxliEiSuhkikqRuhogkqZshIknqtniuBzDbjjvuuDr55JPnehiSNK/cd999z1fVxJ71BRciJ598Mtu2bZvrYUjSvJLk/4yqeztLktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUbW4gkeWuSe5J8P8mOJH/Y6jcleSLJA21Z3upJcl2SySTbk7xv6FhrkjzWljVD9TOSPNj6XJck4zofSdLexvk9kVeBs6vqx0kOB76T5Btt3+9V1W17tD8PWNaWs4AbgLOSHAtcCawACrgvyaaqeqG1WQvcBWwGVgHfQJI0K8Z2JVIDP26bh7dlfz9eshq4ufW7Czg6yQnAucDWqtrVgmMrsKrtO6qqvluDH0W5GbhgXOcjSdrbWL+xnmQRcB/wq8D1VXV3ko8D1yb5A+AO4IqqehVYAjw11H2q1fZXnxpRHzWOtQyuWDjppJPe0Dmd8Xs3v6H+enO67z9cPNdDAOAHV797roegQ9BJf/Dg2I491gfrVfVaVS0HlgJnJjkN+DTwD4F/BBwLfKo1H/U8ozrqo8axrqpWVNWKiYm9Xv0iSeo0K7OzqupF4JvAqqp6pt2yehX4InBmazYFnDjUbSnw9AHqS0fUJUmzZJyzsyaSHN3WjwR+Hfjr9iyDNpPqAuCh1mUTcHGbpbUSeKmqngG2AOckOSbJMcA5wJa27+UkK9uxLgZuH9f5SJL2Ns5nIicAG9pzkcOAW6vq60n+KskEg9tRDwD/prXfDJwPTAKvAJcAVNWuJNcA97Z2V1fVrrb+ceAm4EgGs7KcmSVJs2hsIVJV24HTR9TP3kf7Ai7bx771wPoR9W3AaW9spJKkXn5jXZLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSt7GFSJK3JrknyfeT7Ejyh61+SpK7kzyW5JYkR7T6W9r2ZNt/8tCxPt3qjyY5d6i+qtUmk1wxrnORJI02ziuRV4Gzq+q9wHJgVZKVwGeBz1fVMuAF4NLW/lLghar6VeDzrR1JTgUuBN4FrAK+kGRRkkXA9cB5wKnARa2tJGmWjC1EauDHbfPwthRwNnBbq28ALmjrq9s2bf8Hk6TVN1bVq1X1BDAJnNmWyap6vKp+CmxsbSVJs2Ssz0TaFcMDwHPAVuB/Ay9W1e7WZApY0taXAE8BtP0vAW8bru/RZ1/1UeNYm2Rbkm07d+48GKcmSWLMIVJVr1XVcmApgyuHd45q1j6zj32vtz5qHOuqakVVrZiYmDjwwCVJMzIrs7Oq6kXgm8BK4Ogki9uupcDTbX0KOBGg7f8lYNdwfY8++6pLkmbJOGdnTSQ5uq0fCfw68AhwJ/Dh1mwNcHtb39S2afv/qqqq1S9ss7dOAZYB9wD3AsvabK8jGDx83zSu85Ek7W3xgZt0OwHY0GZRHQbcWlVfT/IwsDHJZ4D7gRtb+xuBLyWZZHAFciFAVe1IcivwMLAbuKyqXgNIcjmwBVgErK+qHWM8H0nSHsYWIlW1HTh9RP1xBs9H9qz/P+Aj+zjWtcC1I+qbgc1veLCSpC5+Y12S1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUbWwhkuTEJHcmeSTJjiS/0+pXJflhkgfacv5Qn08nmUzyaJJzh+qrWm0yyRVD9VOS3J3ksSS3JDliXOcjSdrbOK9EdgOfrKp3AiuBy5Kc2vZ9vqqWt2UzQNt3IfAuYBXwhSSLkiwCrgfOA04FLho6zmfbsZYBLwCXjvF8JEl7GFuIVNUzVfW9tv4y8AiwZD9dVgMbq+rVqnoCmATObMtkVT1eVT8FNgKrkwQ4G7it9d8AXDCes5EkjTIrz0SSnAycDtzdSpcn2Z5kfZJjWm0J8NRQt6lW21f9bcCLVbV7j/qov782ybYk23bu3HkQzkiSBLMQIkl+AfgK8Imq+hFwA/AOYDnwDPC56aYjuldHfe9i1bqqWlFVKyYmJl7nGUiS9mXxOA+e5HAGAfIXVfVVgKp6dmj/nwNfb5tTwIlD3ZcCT7f1UfXngaOTLG5XI8PtJUmzYJyzswLcCDxSVX8yVD9hqNmHgIfa+ibgwiRvSXIKsAy4B7gXWNZmYh3B4OH7pqoq4E7gw63/GuD2cZ2PJGlv47wSeT/w28CDSR5otd9nMLtqOYNbT08CHwOoqh1JbgUeZjCz67Kqeg0gyeXAFmARsL6qdrTjfQrYmOQzwP0MQkuSNEvGFiJV9R1GP7fYvJ8+1wLXjqhvHtWvqh5nMHtLkjQH/Ma6JKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuYwuRJCcmuTPJI0l2JPmdVj82ydYkj7XPY1o9Sa5LMplke5L3DR1rTWv/WJI1Q/UzkjzY+lyXJOM6H0nS3sZ5JbIb+GRVvRNYCVyW5FTgCuCOqloG3NG2Ac4DlrVlLXADDEIHuBI4CzgTuHI6eFqbtUP9Vo3xfCRJe5hRiCS5Yya1YVX1TFV9r62/DDwCLAFWAxtasw3ABW19NXBzDdwFHJ3kBOBcYGtV7aqqF4CtwKq276iq+m5VFXDz0LEkSbNg8f52Jnkr8HPAce3//U/fLjoK+OWZ/pEkJwOnA3cDx1fVMzAImiRvb82WAE8NdZtqtf3Vp0bUJUmzZL8hAnwM+ASDwLiPn4XIj4DrZ/IHkvwC8BXgE1X1o/08thi1ozrqo8awlsFtL0466aQDDVmSNEP7vZ1VVf+xqk4B/m1V/f2qOqUt762qPzvQwZMcziBA/qKqvtrKz7ZbUbTP51p9CjhxqPtS4OkD1JeOqI86j3VVtaKqVkxMTBxo2JKkGZrRM5Gq+tMk/zjJv0hy8fSyvz5tptSNwCNV9SdDuzYB0zOs1gC3D9UvbrO0VgIvtdteW4BzkhzTbqmdA2xp+15OsrL9rYuHjiVJmgUHup0FQJIvAe8AHgBea+Xph9n78n7gt4EHkzzQar8P/BFwa5JLgR8AH2n7NgPnA5PAK8AlAFW1K8k1wL2t3dVVtautfxy4CTgS+EZbJEmzZEYhAqwATm2zoGakqr7D6OcWAB8c0b6Ay/ZxrPXA+hH1bcBpMx2TJOngmun3RB4C/t44ByJJmn9meiVyHPBwknuAV6eLVfXPxzIqSdK8MNMQuWqcg5AkzU8zCpGq+ta4ByJJmn9mOjvrZX72Rb4jgMOBn1TVUeMamCTp0DfTK5FfHN5OcgGDlyFKkhawrrf4VtV/Bc4+yGORJM0zM72d9ZtDm4cx+N7IjL8zIkl6c5rp7KzfGFrfDTzJ4NXtkqQFbKbPRC4Z90AkSfPPTH+UammSryV5LsmzSb6SZOmBe0qS3sxm+mD9iwzesvvLDH746b+1miRpAZtpiExU1RerandbbgL8YQ5JWuBmGiLPJ/mtJIva8lvA34xzYJKkQ99MQ+RfAR8F/i/wDPBh2u99SJIWrplO8b0GWFNVLwAkORb4YwbhIklaoGZ6JfKe6QCBwa8NAqePZ0iSpPlipiFyWPt9c+DvrkRmehUjSXqTmmkQfA74X0luY/C6k48C145tVJKkeWGm31i/Ock2Bi9dDPCbVfXwWEcmSTrkzfiWVAsNg0OS9He6XgU/E0nWt9ekPDRUuyrJD5M80Jbzh/Z9OslkkkeTnDtUX9Vqk0muGKqfkuTuJI8luSXJEeM6F0nSaGMLEeAmYNWI+ueranlbNgMkORW4EHhX6/OF6S82AtcD5wGnAhe1tgCfbcdaBrwAXDrGc5EkjTC2EKmqbwO7Zth8NbCxql6tqieASQa/nHgmMFlVj1fVT4GNwOokYfB85rbWfwNwwUE9AUnSAY3zSmRfLk+yvd3ump42vAR4aqjNVKvtq/424MWq2r1HfaQka5NsS7Jt586dB+s8JGnBm+0QuQF4B7CcwetTPtfqGdG2OuojVdW6qlpRVSsmJnxvpCQdLLP6hcGqenZ6PcmfA19vm1PAiUNNlwJPt/VR9eeBo5Msblcjw+0lSbNkVq9EkpwwtPkhYHrm1ibgwiRvSXIKsAy4B7gXWNZmYh3B4OH7pqoq4E4GL4IEWAPcPhvnIEn6mbFdiST5MvAB4LgkU8CVwAeSLGdw6+lJ4GMAVbUjya0MvoeyG7isql5rx7kc2AIsAtZX1Y72Jz4FbEzyGeB+4MZxnYskabSxhUhVXTSivM//0FfVtYx4lUqbBrx5RP1xBrO3JElzZC5mZ0mS3iQMEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3cYWIknWJ3kuyUNDtWOTbE3yWPs8ptWT5Lokk0m2J3nfUJ81rf1jSdYM1c9I8mDrc12SjOtcJEmjjfNK5CZg1R61K4A7qmoZcEfbBjgPWNaWtcANMAgd4ErgLOBM4Mrp4Glt1g712/NvSZLGbGwhUlXfBnbtUV4NbGjrG4ALhuo318BdwNFJTgDOBbZW1a6qegHYCqxq+46qqu9WVQE3Dx1LkjRLZvuZyPFV9QxA+3x7qy8BnhpqN9Vq+6tPjaiPlGRtkm1Jtu3cufMNn4QkaeBQebA+6nlGddRHqqp1VbWiqlZMTEx0DlGStKfZDpFn260o2udzrT4FnDjUbinw9AHqS0fUJUmzaLZDZBMwPcNqDXD7UP3iNktrJfBSu921BTgnyTHtgfo5wJa27+UkK9usrIuHjiVJmiWLx3XgJF8GPgAcl2SKwSyrPwJuTXIp8APgI635ZuB8YBJ4BbgEoKp2JbkGuLe1u7qqph/Wf5zBDLAjgW+0RZI0i8YWIlV10T52fXBE2wIu28dx1gPrR9S3Aae9kTFKkt6YQ+XBuiRpHjJEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1G1OQiTJk0keTPJAkm2tdmySrUkea5/HtHqSXJdkMsn2JO8bOs6a1v6xJGvm4lwkaSGbyyuRf1ZVy6tqRdu+ArijqpYBd7RtgPOAZW1ZC9wAg9ABrgTOAs4ErpwOHknS7DiUbmetBja09Q3ABUP1m2vgLuDoJCcA5wJbq2pXVb0AbAVWzfagJWkhm6sQKeAvk9yXZG2rHV9VzwC0z7e3+hLgqaG+U622r/pekqxNsi3Jtp07dx7E05CkhW3xHP3d91fV00neDmxN8tf7aZsRtdpPfe9i1TpgHcCKFStGtpEkvX5zciVSVU+3z+eArzF4pvFsu01F+3yuNZ8CThzqvhR4ej91SdIsmfUQSfLzSX5xeh04B3gI2ARMz7BaA9ze1jcBF7dZWiuBl9rtri3AOUmOaQ/Uz2k1SdIsmYvbWccDX0sy/ff/c1X99yT3ArcmuRT4AfCR1n4zcD4wCbwCXAJQVbuSXAPc29pdXVW7Zu80JEmzHiJV9Tjw3hH1vwE+OKJewGX7ONZ6YP3BHqMkaWYOpSm+kqR5xhCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktRt3odIklVJHk0ymeSKuR6PJC0k8zpEkiwCrgfOA04FLkpy6tyOSpIWjnkdIsCZwGRVPV5VPwU2AqvneEyStGAsnusBvEFLgKeGtqeAs/ZslGQtsLZt/jjJo7MwtoXgOOD5uR7EoSB/vGauh6C9+e9z2pU5GEf5lVHF+R4io/6Xqb0KVeuAdeMfzsKSZFtVrZjrcUij+O9zdsz321lTwIlD20uBp+doLJK04Mz3ELkXWJbklCRHABcCm+Z4TJK0YMzr21lVtTvJ5cAWYBGwvqp2zPGwFhJvEepQ5r/PWZCqvR4hSJI0I/P9dpYkaQ4ZIpKkboaIuvi6GR2qkqxP8lySh+Z6LAuBIaLXzdfN6BB3E7BqrgexUBgi6uHrZnTIqqpvA7vmehwLhSGiHqNeN7NkjsYiaQ4ZIuoxo9fNSHrzM0TUw9fNSAIMEfXxdTOSAENEHapqNzD9uplHgFt93YwOFUm+DHwX+AdJppJcOtdjejPztSeSpG5eiUiSuhkikqRuhogkqZshIknqZohIkroZItIhKsk3k6xo65uTHD3XY5L2NK9/Hld6s0iyuH3/ZqSqOn82xyPNlFci0kGW5OIk25N8P8mXkvxGkruT3J/kfyQ5vrW7Ksm6JH8J3JzkyCQbW99bgCOHjvlkkuPa+u8meagtn5ibs5QGvBKRDqIk7wL+PfD+qno+ybEMXk65sqoqyb8G/h3wydblDODXqupvk/wu8EpVvSfJe4DvjTj+GcAlwFkMXoR5d5JvVdX94z87aW+GiHRwnQ3cVlXPA1TVriTvBm5JcgJwBPDEUPtNVfW3bf2fAte1ftuTbB9x/F8DvlZVPwFI8lXgnwCGiOaEt7Okgyvs/Vr8PwX+rKreDXwMeOvQvp/s0fZA7yEa9Rp+ac4YItLBdQfw0SRvA2i3s34J+GHbv2Y/fb8N/MvW7zTgPftoc0GSn0vy88CHgP95kMYuvW7ezpIOoqrakeRa4FtJXmNwm+kq4L8k+SFwF3DKPrrfAHyx3cZ6ALhnxPG/l+SmoX3/yechmku+xVeS1M3bWZKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSer2/wHFpSoFtZXzdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.cardio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vari√°veis num√©ricas continuas  est√£o em escalas diferentes. Necess√°rio normalizar. Optei por usar o MinMaxScaler, pois o StandardScaler estava causando NaN no calculo do custo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T06:21:32.409933Z",
     "start_time": "2020-03-16T06:21:32.332977Z"
    }
   },
   "outputs": [],
   "source": [
    "mmsc = MinMaxScaler()\n",
    "variaveis_continuas = [\"age\", \"height\", \"weight\", \"ap_hi\", \"ap_lo\", \"cholesterol\"]\n",
    "df[variaveis_continuas] = mmsc.fit(df[variaveis_continuas]).transform(df[variaveis_continuas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como a vari√°vel Sexo √© bin√°ria, troquei o valor 2 por 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T06:21:34.171479Z",
     "start_time": "2020-03-16T06:21:34.166031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    45530\n",
       "2    24470\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T06:21:34.654215Z",
     "start_time": "2020-03-16T06:21:34.623641Z"
    }
   },
   "outputs": [],
   "source": [
    "df.gender = df.gender.apply(lambda genero: 0 if genero == 2 else genero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split como modo de valida√ß√£o. Os sets de X foram transpostos de modo que cada coluna seja um exemplo e cada linha seja uma feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T06:27:37.444663Z",
     "start_time": "2020-03-16T06:27:37.421663Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = df.iloc[:,:-1].to_numpy(), df.iloc[:,-1].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "y_train = y_train.reshape((1, X_train.shape[1]))\n",
    "y_test = y_test.reshape((1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cada layer ter√° uma matriz de pesos W e um vetor bias b associado. A dimens√£o da matriz W √© definida com a quantidade de linhas sendo igual a quantidade de nodos no layer e a quantidade colunas como a quantidade de inputs do layer. O vetor bias ter√° um bias para cada nodo layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-15T23:43:13.558425Z",
     "start_time": "2020-03-15T23:43:13.552432Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_parametros_iniciais(tamanho_layers):\n",
    "    np.random.seed(1)\n",
    "    parametros = []\n",
    "    for indice in range(1,len(tamanho_layers)):\n",
    "        parametros.append([np.random.randn(tamanho_layers[indice], tamanho_layers[indice-1]) * (2/np.sqrt(tamanho_layers[indice-1])),\n",
    "                           np.zeros((tamanho_layers[indice], 1))])\n",
    "    return parametros\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defini√ß√£o das fun√ß√µes de ativa√ß√£o utilizadas: sigm√≥ide e relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T06:30:30.248467Z",
     "start_time": "2020-03-16T06:30:30.242754Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    return A\n",
    "\n",
    "def softsign(Z):\n",
    "    A = np.divide(Z, (1+np.abs(Z)))\n",
    "    return A\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T18:47:53.154687Z",
     "start_time": "2020-03-11T18:47:53.149470Z"
    }
   },
   "source": [
    "### Esquema forward propagation\n",
    "<img src=\"imagens/model_architecture_kiank.png\" style=\"width:600px;height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O output do layer l √© calculado conforme indicado abaixo, sendo A^[0] os dados de treino\n",
    "$$ A^{[l]} = \\theta(  (W^{[l]})^{T} \\cdot A^{[l-1]} + b^{[l]}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T06:31:33.054742Z",
     "start_time": "2020-03-16T06:31:33.049658Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parametros, funcao_ativacao=relu):\n",
    "    cache = []\n",
    "    A = X\n",
    "    quantidade_layers = len(parametros)\n",
    "    for indice_layer in range(0, quantidade_layers-1): # foward propagation at√© o ultimo layer antes do layer output\n",
    "        W, b = parametros[indice_layer]\n",
    "        Z = np.dot(W, A) + b\n",
    "        cache.append((A, Z, W, b))\n",
    "        A = funcao_ativacao(Z)\n",
    "    W, b = parametros[indice_layer+1] # como √© um problema de classificao, o √∫ltimo layer deve obrigatoriamente ter\n",
    "                                      #  a funcao sigmoide como funcao de ativa√ß√£o\n",
    "    \n",
    "    Z = np.dot(W, A) + b\n",
    "    cache.append((A, Z, W, b))\n",
    "    A = sigmoid(Z)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A fun√ß√£o custo ùúÅ com regulariza√ß√£o L2 √© definida abaixo, com m sendo a quantidade de exemplos usados no treino: $$\\zeta = -\\frac{1}{m} \\sum\\limits_{i = 0}^{m} (y^{(i)}\\log\\left(A^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- A^{[L](i)}\\right)) +¬†\\lambda/(2*m)*\\sum\\limits_{l = 0}^{L} ||W^{(l)})||^{2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T06:42:37.194562Z",
     "start_time": "2020-03-16T06:42:37.188774Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_custo(A, Y, lambd, parametros):    \n",
    "    m = Y.shape[1]\n",
    "    l2 = lambd/(2*m) * np.sum([np.sum(np.square(w)) for w in parametros[:][0]])\n",
    "    custo = (1./m) * (-np.dot(Y,np.log(A).T) - np.dot(1-Y, np.log(1-A).T)) + l2\n",
    "    custo = float(np.squeeze(custo))\n",
    "    return custo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Os gradientes do layer l s√£o definidos abaixo, sendo L o √≠ndice do √∫ltimo layer, A a fun√ß√£o de ativa√ß√£o e Z a fun√ß√£o linear\n",
    "\n",
    "$$ \\frac{\\partial \\zeta}{\\partial W^{[l]}} = \\frac{\\partial \\zeta}{\\partial A^{[L]}} * \\prod_{i=L}^{l+1}(\\frac{\\partial A^{[i]}}{\\partial Z^{[i]}}*\\frac{\\partial Z^{[i]}}{\\partial A^{[i-1]}}) * \\frac{\\partial A^{[l]}}{\\partial Z^{[l]}} * \\frac{\\partial Z^{[l]}}{\\partial W^{[l]}} $$\n",
    "\n",
    "$$ \\frac{\\partial \\zeta}{\\partial b^{[l]}} = \\frac{\\partial \\zeta}{\\partial A^{[L]}} * \\prod_{i=L}^{l+1}(\\frac{\\partial A^{[i]}}{\\partial Z^{[i]}}*\\frac{\\partial Z^{[i]}}{\\partial A^{[i-1]}}) * \\frac{\\partial A^{[i]}}{\\partial Z^{[i]}} * \\frac{\\partial Z^{[l]}}{\\partial b^{[l]}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T07:44:12.345560Z",
     "start_time": "2020-03-16T07:44:12.338188Z"
    }
   },
   "outputs": [],
   "source": [
    "def derivada_relu(dA, Z):\n",
    "    dZ = np.array(dA, copy=True) \n",
    "    dZ[Z <= 0] = 0\n",
    "    return dZ\n",
    "\n",
    "def derivada_softsign(dA, Z):\n",
    "    return np.multiply(dA, np.divide(1, np.multiply(1+Z, 1+Z)))\n",
    "\n",
    "def derivada_sigmoide(dA, Z):\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-15T23:43:15.313120Z",
     "start_time": "2020-03-15T23:43:15.293060Z"
    }
   },
   "outputs": [],
   "source": [
    "def backward_propagation(A, cache, Y, funcao_ativacao_derivada=derivada_relu):\n",
    "    m = A.shape[1]\n",
    "    Y = Y.reshape(A.shape)\n",
    "    gradientes = []\n",
    "    \n",
    "    dA = - (np.divide(Y, A) - np.divide(1 - Y, 1 - A))\n",
    "    A_prev, Z, W, b = cache[-1]\n",
    "    dZ = derivada_sigmoide(dA, Z)\n",
    "\n",
    "    dA_layer_anterior = np.dot(W.T, dZ)\n",
    "    dW = np.dot(dZ, A_prev.T) / m\n",
    "    db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "    gradientes.append([dW, db])\n",
    "\n",
    "    for cache_ in cache[::-1][1:]:\n",
    "        dA = dA_layer_anterior\n",
    "        A_prev, Z, W, b = cache_\n",
    "        dZ = funcao_ativacao_derivada(dA, Z)\n",
    "\n",
    "        dA_layer_anterior = np.dot(W.T, dZ)\n",
    "        dW = np.dot(dZ, A_prev.T) / m\n",
    "        db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "        gradientes.append([dW, db])\n",
    "        \n",
    "    return gradientes[::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A atualiza√ß√£o dos par√¢metros do layer l √© definido a seguir, sendo alfa a taxa de aprendizado, lambda o coeficiente da regulariza√ß√£o L2 e m o tamanho do dataset utilizado no treino\n",
    "### $$ W^{[l]} = W^{[l]} - \\alpha * ( \\frac{\\partial \\zeta}{\\partial W^{[l]}} + \\lambda/m*W^{[L]})$$\n",
    "### $$ b^{[l]} = b^{[l]} - \\alpha *  \\frac{\\partial \\zeta}{\\partial b^{[l]}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-15T23:43:15.717628Z",
     "start_time": "2020-03-15T23:43:15.706519Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_parametros_atualizados(parametros, gradientes, m, lambd, taxa_aprendizado=0.05):\n",
    "    L = len(parametros) \n",
    "    for l in range(L):\n",
    "        parametros[l][0] -= taxa_aprendizado * (gradientes[l][0] + lambd/m * parametros[l][0])\n",
    "        parametros[l][1] -= taxa_aprendizado * gradientes[l][1] \n",
    "    return parametros\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T08:37:14.277369Z",
     "start_time": "2020-03-16T08:37:14.266456Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(X, Y, taxa_aprendizado, iteracoes, tamanhos_layers, lambd=0.7, tamanho_batch=5000):\n",
    "    global gradientes\n",
    "    global parametros\n",
    "    quantidade_batchs = X.shape[1] // tamanho_batch\n",
    "    \n",
    "    parametros = get_parametros_iniciais(tamanhos_layers)\n",
    "    custos = []\n",
    "    for iteracao in range(iteracoes):\n",
    "        for batch in range(quantidade_batchs-1):\n",
    "            x = X[:, tamanho_batch*batch:tamanho_batch*tamanho_batch*(batch+1)]\n",
    "            y = Y[:, tamanho_batch*batch:tamanho_batch*tamanho_batch*(batch+1)]\n",
    "            A, cache = forward_propagation(x, parametros)\n",
    "            custo = get_custo(A, y, lambd, parametros)\n",
    "            custos.append(custo)\n",
    "            gradientes = backward_propagation(A, cache, y)\n",
    "            parametros = get_parametros_atualizados(parametros, gradientes, x.shape[1], lambd, taxa_aprendizado)\n",
    "        x = X[:,tamanho_batch*(batch+1):]\n",
    "        y = Y[:, tamanho_batch*(batch+1):]\n",
    "        A, cache = forward_propagation(x, parametros)\n",
    "        custo = get_custo(A, y, lambd, parametros)\n",
    "        custos.append(custo)\n",
    "        gradientes = backward_propagation(A, cache, y)\n",
    "        parametros = get_parametros_atualizados(parametros, gradientes, x.shape[1], lambd, taxa_aprendizado)\n",
    "        if iteracao % 100 == 0:\n",
    "            print(\"Itera√ß√£o: {} | Custo: {}\".format(iteracao, custo))\n",
    "    \n",
    "    return parametros, custos        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-15T23:44:09.360913Z",
     "start_time": "2020-03-15T23:44:09.357892Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(X, Y, parametros):\n",
    "    A, cache = forward_propagation(X, parametros)\n",
    "    return np.round(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-15T23:44:09.894162Z",
     "start_time": "2020-03-15T23:44:09.886510Z"
    }
   },
   "outputs": [],
   "source": [
    "# def converte_array_em_parametros(array, tamanho_layers):\n",
    "#     parametros = []\n",
    "#     for index in range(1, len(tamanho_layers)):\n",
    "#         w_shape_linear = tamanho_layers[index]*tamanho_layers[index-1]\n",
    "#         w = array[:w_shape_linear].reshape((tamanho_layers[index], tamanho_layers[index-1]))\n",
    "#         b = array[w_shape_linear:w_shape_linear + tamanho_layers[index]].reshape((tamanho_layers[index], 1))\n",
    "#         parametros.append([w, b])\n",
    "#         array = array[w_shape_linear + tamanho_layers[index]:]\n",
    "#     return parametros\n",
    "\n",
    "# def verifica_backpropagation(parametros, gradientes, tamanho_layers, X, Y, epsilon=1e-7):\n",
    "#     parameters_values = np.concatenate([np.concatenate([parametro[0].flatten(), parametro[1].flatten()]) \n",
    "#                                        for parametro in parametros])\n",
    "#     grads =  np.concatenate([np.concatenate([gradiente[0].flatten(), gradiente[1].flatten()]) \n",
    "#                                        for gradiente in gradientes])\n",
    "    \n",
    "#     num_parameters = parameters_values.shape[0]\n",
    "#     J_plus = np.zeros((num_parameters, 1))\n",
    "#     J_minus = np.zeros((num_parameters, 1))\n",
    "#     gradapprox = np.zeros((num_parameters, 1))\n",
    "    \n",
    "#     for i in range(num_parameters):\n",
    "        \n",
    "#         # Compute J_plus[i]. Inputs: \"parameters_values, epsilon\". Output = \"J_plus[i]\".\n",
    "#         # \"_\" is used because the function you have to outputs two parameters but we only care about the first one\n",
    "#         ### START CODE HERE ### (approx. 3 lines)\n",
    "#         thetaplus =  np.copy(parameters_values)                                       # Step 1\n",
    "#         thetaplus[i] = thetaplus[i] + epsilon                                   # Step 2\n",
    "#         A, _ =  forward_propagation(X, converte_array_em_parametros(thetaplus, tamanho_layers))  # Step 3\n",
    "#         J_plus[i][0] = get_custo(A, Y, 0.7, converte_array_em_parametros(thetaplus, tamanho_layers))\n",
    "#         ### END CODE HERE ###\n",
    "        \n",
    "#         # Compute J_minus[i]. Inputs: \"parameters_values, epsilon\". Output = \"J_minus[i]\".\n",
    "#         ### START CODE HERE ### (approx. 3 lines)\n",
    "#         thetaminus = np.copy(parameters_values)                                       # Step 1\n",
    "#         thetaminus[i] = thetaminus[i] - epsilon                                 # Step 2       \n",
    "#         A, _ = forward_propagation(X, converte_array_em_parametros(thetaminus, tamanho_layers)) # Step 3\n",
    "#         J_minus[i][0] = get_custo(A, Y, 0.7, converte_array_em_parametros(thetaminus, tamanho_layers))\n",
    "#         ### END CODE HERE ###\n",
    "        \n",
    "#         # Compute gradapprox[i]\n",
    "#         ### START CODE HERE ### (approx. 1 line)\n",
    "#         gradapprox[i] = (J_plus[i] - J_minus[i]) / (2 * epsilon)\n",
    "#         ### END CODE HERE ###\n",
    "    \n",
    "#     # Compare gradapprox to backward propagation gradients by computing difference.\n",
    "#     ### START CODE HERE ### (approx. 1 line)\n",
    "#     numerator = np.linalg.norm(grads - gradapprox)                                     # Step 1'\n",
    "#     denominator = np.linalg.norm(grads) + np.linalg.norm(gradapprox)                   # Step 2'\n",
    "#     difference = numerator / denominator                                              # Step 3'\n",
    "#     ### END CODE HERE ###\n",
    "\n",
    "#     if difference > 1e-7:\n",
    "#         print(\"\\033[93m\" + \"There is a mistake in the backward propagation! difference = \" + str(difference) + \"\\033[0m\")\n",
    "#     else:\n",
    "#         print(\"\\033[92m\" + \"Your backward propagation works perfectly fine! difference = \" + str(difference) + \"\\033[0m\")\n",
    "    \n",
    "#     return difference\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T00:15:29.531957Z",
     "start_time": "2020-03-16T00:13:56.294400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itera√ß√£o: 0 | Custo: 0.6934329062095833\n",
      "Itera√ß√£o: 100 | Custo: 0.6331354079148583\n",
      "Itera√ß√£o: 200 | Custo: 0.630004494681168\n",
      "Itera√ß√£o: 300 | Custo: 0.6287941360758122\n",
      "Itera√ß√£o: 400 | Custo: 0.6281538550397969\n",
      "Itera√ß√£o: 500 | Custo: 0.6274898345505289\n",
      "Itera√ß√£o: 600 | Custo: 0.6271929605630615\n",
      "Itera√ß√£o: 700 | Custo: 0.6267877682942343\n",
      "Itera√ß√£o: 800 | Custo: 0.6263759164013601\n",
      "Itera√ß√£o: 900 | Custo: 0.6260934278301121\n"
     ]
    }
   ],
   "source": [
    "tamanho_layers = [11, 8, 4, 2, 1]\n",
    "gradientes = []\n",
    "parametros = []\n",
    "parametros, custos = fit(X_train, y_train, 0.05, 1000, tamanho_layers, lambd=0.4, tamanho_batch=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T00:15:29.551798Z",
     "start_time": "2020-03-16T00:15:29.533328Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pred = predict(X_train, y_train, parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T00:15:29.652837Z",
     "start_time": "2020-03-16T00:15:29.555999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.655976171509715"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train[0], train_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T00:15:29.669565Z",
     "start_time": "2020-03-16T00:15:29.661169Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred = predict(X_test, y_test, parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T00:15:29.703855Z",
     "start_time": "2020-03-16T00:15:29.679647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6610590182018755"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test[0], test_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T00:15:29.736585Z",
     "start_time": "2020-03-16T00:15:29.720427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6488571428571429"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[0], test_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
